{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f9ebdc8-c55e-4276-964a-4cc0b6dbf42c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T09:49:38.798081941Z",
     "start_time": "2023-10-22T09:49:36.252027990Z"
    },
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.34.1)\r\nRequirement already satisfied: pymongo in /usr/local/lib/python3.10/dist-packages (4.5.0)\r\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.12.4)\r\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.17.3)\r\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.24.1)\r\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.1)\r\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\r\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.10.3)\r\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.28.1)\r\nRequirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.14.1)\r\nRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.0)\r\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\r\nRequirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.0.1+cu118)\r\nRequirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.23.0)\r\nRequirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo) (2.4.2)\r\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\r\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (2023.10.0)\r\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.4.0)\r\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.11.1)\r\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.0)\r\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\r\nRequirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.0.0)\r\nRequirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.10->transformers[torch]) (3.25.0)\r\nRequirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.10->transformers[torch]) (15.0.7)\r\nRequirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.1.1)\r\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.4)\r\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (1.26.13)\r\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2022.12.7)\r\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.2)\r\nRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.2.1)\r\n\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\r\n\u001B[0m\r\n\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.1.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.3.1\u001B[0m\r\n\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpython -m pip install --upgrade pip\u001B[0m\r\n"
    }
   ],
   "source": [
    "!pip install transformers[torch] pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f60de649-2629-4050-a6a0-ba97bde1150f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T09:50:16.298133280Z",
     "start_time": "2023-10-22T09:49:38.797665268Z"
    },
    "trusted": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81cf701a8d18409395af346150f5aeb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model = \"tiiuae/falcon-7b-instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37d2359ebb1a8286",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T09:50:16.303743417Z",
     "start_time": "2023-10-22T09:50:16.292123092Z"
    },
    "collapsed": false,
    "trusted": false
   },
   "outputs": [],
   "source": [
    "def analyze_survey_response(target=\"Jim\", survey_response=\"He seems really sad, and he's been drinking a lot lately.\"):\n",
    "    prompt = f\"\"\"\\\n",
    "You are provided with an anonymous survey response about a construction worker {target}. According to the response, might {target} be at risk for mental health issues? If so, are they lonely, depressed, anxious, or any combination of those issues? If so, list what you think they might be at risk for as a list of conditions separated by commas, or a single condition. Do not provide further text after your answer. If {target} does not seem at risk for any mental health issues, just answer \"no\" without any further text.\n",
    "\n",
    "Survey response: \"{survey_response}\" \n",
    "\n",
    "Answer: \"\"\"\n",
    "    sequences = pipeline(\n",
    "        prompt,\n",
    "        max_new_tokens=100,\n",
    "        do_sample=True,\n",
    "        # top_k=1,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    response = sequences[0]['generated_text']\n",
    "    # return last line\n",
    "    response = response.splitlines()[-1]\n",
    "    print(response)\n",
    "    # extract from answer token\n",
    "    if \"Answer: \" in response:\n",
    "        response = response.split(\"Answer: \")[1].strip()\n",
    "    # remove quotes\n",
    "    response = response.replace('\"', \"\")\n",
    "    # split on commas and trim whitespace\n",
    "    response = [r.strip() for r in response.split(\",\")]\n",
    "    return response\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f749fe58f0c3df4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T09:50:16.304570826Z",
     "start_time": "2023-10-22T09:50:16.296841915Z"
    },
    "collapsed": false,
    "trusted": false
   },
   "outputs": [],
   "source": [
    "def analyze_report(survey_responses: list[str], voice_response=None):\n",
    "    nl = '\\n'\n",
    "    prompt = f\"\"\"\\\n",
    "Your task is to provide a construction manager advice on how to improve the mental health of their workers. For example, if a coworker is feeling isolated, you might suggest that the manager organize a team-building event. If a worker is feeling depressed, you might suggest the manager to provide the team with a mental health day. If a worker is feeling anxious, you might suggest the manager to provide the team with a day off. If a worker is feeling stressed, you might suggest the manager to provide the team with stress relieving activities. If a worker is feeling burnt out, you might suggest the manager to provide the team with a day off. If a worker is feeling exhausted, you might suggest the manager to provide the team with additional rest breaks.\n",
    "You must not reveal the identity of anyone in your advice, because the employer might use this information to persecute the worker. Do not use anyone's name or any personal information in the surveys in your response.\n",
    "\n",
    "You are provided with the results of various surveys about a construction worker. The goal of these surveys is to address the mental health of the worker based on the opinions and perspectives of their coworkers. The surveys are as follows:\n",
    "\n",
    "###\n",
    "{nl.join(survey_responses)}\n",
    "###\n",
    "\n",
    "\"\"\"\n",
    "    voice_prompt = f\"\"\"\\\n",
    "When you recieved these survey responses, you called the worker to ask how they are doing. The worker responded with the following:\n",
    "###\n",
    "{voice_response}\n",
    "###\n",
    "\"\"\" if voice_response else \"\"\n",
    "\n",
    "    # add voice prompt to prompt\n",
    "    prompt += voice_prompt\n",
    "\n",
    "    # add question\n",
    "    prompt += f\"\"\"\\\n",
    "Based on the feedback of the worker in the phone call and the survey responses of the coworkers, construct a text message to be sent to the manager that will suggest an action to improve the mental health of the team. The message should be no longer than 160 characters.\n",
    "\n",
    "\n",
    "This is how you should format your responses:\n",
    "###\n",
    "Your team is feeling isolated. Consider organizing a team-building event.\n",
    "Your team is feeling depressed. Consider providing the team with a mental health day.\n",
    "Your team is feeling anxious. Consider providing the team with a day off.\n",
    "Your team is feeling stressed. Consider providing the team with stress relieving activities.\n",
    "###\n",
    "\n",
    "Message to the manager:\\\n",
    "\"\"\"\n",
    "\n",
    "    sequences = pipeline(\n",
    "        prompt,\n",
    "        max_new_tokens=100,\n",
    "        do_sample=True,\n",
    "        # top_k=1,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    response = sequences[0]['generated_text']\n",
    "    # extract from answer token\n",
    "    response = response.split(\"Message to the manager:\")[1].strip()\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b785dba08f6fc6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-22T09:50:16.297496537Z"
    },
    "collapsed": false,
    "is_executing": true,
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "{'version': '6.0.11', 'gitVersion': 'f797f841eaf1759c770271ae00c88b92b2766eed', 'modules': ['enterprise'], 'allocator': 'tcmalloc', 'javascriptEngine': 'mozjs', 'sysInfo': 'deprecated', 'versionArray': [6, 0, 11, 0], 'bits': 64, 'debug': False, 'maxBsonObjectSize': 16777216, 'storageEngines': ['devnull', 'ephemeralForTest', 'inMemory', 'queryable_wt', 'wiredTiger'], 'ok': 1.0, '$clusterTime': {'clusterTime': Timestamp(1697968251, 143), 'signature': {'hash': b'\\xc0}mR\\xd8\\xd2A\\xf2\\x82\\x0fh\\xad[s\\x1e\\x19\\x048\\x8e\\xc2', 'keyId': 7228200195597533185}}, 'operationTime': Timestamp(1697968251, 143)}\nWatching for changes...\n"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "{'_id': {'_data': '826534F0C6000000212B022C0100296E5A1004067B53CDD06545958AA83AC7AFE3B47A46645F696400646534F0C68D7EA8F79EC793B00004'}, 'operationType': 'insert', 'clusterTime': Timestamp(1697968326, 33), 'wallTime': datetime.datetime(2023, 10, 22, 9, 52, 6, 625000), 'fullDocument': {'_id': ObjectId('6534f0c68d7ea8f79ec793b0'), 'target': 'Tim', 'response': 'He is struggling with his mental health 5'}, 'ns': {'db': 'db', 'coll': 'surveys'}, 'documentKey': {'_id': ObjectId('6534f0c68d7ea8f79ec793b0')}}\n"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "The current implementation of Falcon calls `torch.scaled_dot_product_attention` directly, this will be deprecated in the future in favor of the `BetterTransformer` API. Please install the latest optimum library with `pip install -U optimum` and call `model.to_bettertransformer()` to benefit from `torch.scaled_dot_product_attention` and future performance optimizations.\n"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Answer: \"Lonely, depressed, and anxious\"\nInference time: 3.3475558757781982\nResponse: ['Lonely', 'depressed', 'and anxious']\n{'_id': {'_data': '826534F0CA000000022B022C0100296E5A1004087E1F32086D418F9739A80E48B524C946645F696400646534F0CA56AA64A66DC597D30004'}, 'operationType': 'insert', 'clusterTime': Timestamp(1697968330, 2), 'wallTime': datetime.datetime(2023, 10, 22, 9, 52, 10, 80000), 'fullDocument': {'_id': ObjectId('6534f0ca56aa64a66dc597d3'), 'survey_id': ObjectId('6534f0c68d7ea8f79ec793b0'), 'target': 'Tim', 'survey_response': 'He is struggling with his mental health 5', 'analysis': ['Lonely', 'depressed', 'and anxious'], 'inference_time': 3.3475558757781982}, 'ns': {'db': 'db', 'coll': 'survey_analyses'}, 'documentKey': {'_id': ObjectId('6534f0ca56aa64a66dc597d3')}}\n"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "{'_id': {'_data': '826534F0F3000000192B022C0100296E5A1004A91AB4954746487BADC0A657D87C72DC46645F696400646534F0F28D7EA8F79EC793B10004'}, 'operationType': 'insert', 'clusterTime': Timestamp(1697968371, 25), 'wallTime': datetime.datetime(2023, 10, 22, 9, 52, 51, 279000), 'fullDocument': {'_id': ObjectId('6534f0f28d7ea8f79ec793b1'), 'target': 'Farhan', 'voice_response': 'I have been really stressed out lately and it is affecting my mental health. I am not sure what to do about it.'}, 'ns': {'db': 'db', 'coll': 'voice_transcripts'}, 'documentKey': {'_id': ObjectId('6534f0f28d7ea8f79ec793b1')}}\ngetting data\ncalling pipeline\nInference time: 1.2551789283752441\nResponse: There is an issue with the mental health of some workers. Consider providing the team with extra rest breaks.\n{'_id': {'_data': '826534F0F40000002D2B022C0100296E5A10043F1150212BF04FE1BE571EC24443EC5746645F696400646534F0F456AA64A66DC597D40004'}, 'operationType': 'insert', 'clusterTime': Timestamp(1697968372, 45), 'wallTime': datetime.datetime(2023, 10, 22, 9, 52, 52, 746000), 'fullDocument': {'_id': ObjectId('6534f0f456aa64a66dc597d4'), 'report_id': ObjectId('6534f0f28d7ea8f79ec793b1'), 'target': 'Farhan', 'survey_responses': [], 'voice_response': 'I have been really stressed out lately and it is affecting my mental health. I am not sure what to do about it.', 'body': 'There is an issue with the mental health of some workers. Consider providing the team with extra rest breaks.', 'inference_time': 1.2551789283752441}, 'ns': {'db': 'db', 'coll': 'reports'}, 'documentKey': {'_id': ObjectId('6534f0f456aa64a66dc597d4')}}\n"
    }
   ],
   "source": [
    "import time\n",
    "from pymongo import MongoClient\n",
    "\n",
    "uri = \"mongodb+srv://hacker:ffzK61HllJvM19St@cluster0.acqccxh.mongodb.net/?retryWrites=true&w=majority\"\n",
    "client = MongoClient(uri)\n",
    "\n",
    "# ping server\n",
    "print(client.server_info())\n",
    "\n",
    "db = client['db']\n",
    "\n",
    "survey_analyses = db['survey_analyses']\n",
    "reports = db['reports']\n",
    "\n",
    "# watch for changes\n",
    "print(\"Watching for changes...\")\n",
    "cursor = db.watch(full_document=\"updateLookup\")\n",
    "\n",
    "for change in cursor:\n",
    "    try:\n",
    "        print(change)\n",
    "        # check if survey response or report\n",
    "        if change['ns']['coll'] == 'voice_transcripts':\n",
    "            print(\"getting data\")\n",
    "            # get data\n",
    "            report_id = change['fullDocument']['_id']\n",
    "            target = change['fullDocument']['target']\n",
    "            voice_response = change['fullDocument'].get('voice_response', None)\n",
    "            # get associated survey responses\n",
    "            survey_responses = [x['response'] for x in\n",
    "                                db['surveys'].find({'target': target}, {'response': 1, '_id': 0})]\n",
    "            # call pipeline\n",
    "            print(\"calling pipeline\")\n",
    "            start = time.time()\n",
    "            response = analyze_report(survey_responses, voice_response)\n",
    "            end = time.time()\n",
    "            print('Inference time:', end - start)\n",
    "            print('Response:', response)\n",
    "            # put analysis in report_analyses collection\n",
    "            report = {\n",
    "                \"report_id\": report_id,\n",
    "                \"target\": target,\n",
    "                \"survey_responses\": survey_responses,\n",
    "                \"voice_response\": voice_response,\n",
    "                \"body\": response,\n",
    "                \"inference_time\": end - start,\n",
    "            }\n",
    "            reports.insert_one(report)\n",
    "        elif change['ns']['coll'] == 'surveys':\n",
    "            # get data\n",
    "            survey_id = change['fullDocument']['_id']\n",
    "            target = change['fullDocument']['target']\n",
    "            survey_response = change['fullDocument']['response']\n",
    "            # call pipeline\n",
    "            start = time.time()\n",
    "            response = analyze_survey_response(target, survey_response)\n",
    "            end = time.time()\n",
    "            print('Inference time:', end - start)\n",
    "            print('Response:', response)\n",
    "            # put analysis in survey_analyses collection\n",
    "            survey_analysis = {\n",
    "                \"survey_id\": survey_id,\n",
    "                \"target\": target,\n",
    "                \"survey_response\": survey_response,\n",
    "                \"analysis\": response,\n",
    "                \"inference_time\": end - start,\n",
    "            }\n",
    "            survey_analyses.insert_one(survey_analysis)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
